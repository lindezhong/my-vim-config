# 60,000 毫秒内的 Linux 性能分析
# 这个命令提示是基于: https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55

# cmd: vmstat
# cmd: mpstat
# cmd: pidstat
# cmd: iostat
# cmd: sar
# end

# 您登录到存在性能问题的 Linux 服务器：您在第一分钟会检查什么？
# 在 Netflix，我们拥有庞大的 EC2 Linux 云，以及众多性能分析工具来监控和调查其性能。其中包括用于全云监控的Atlas和用于按需实例分析的Vector。
# 虽然这些工具可以帮助我们解决大多数问题，但有时我们需要登录实例并运行一些标准的 Linux 性能工具。
# 在这篇文章中，Netflix 性能工程团队将使用您应该拥有的标准 Linux 工具，向您展示在命令行上优化性能调查的前 60 秒。
# 在 60 秒内，您可以通过运行以下十个命令来大致了解系统资源使用情况和正在运行的进程。查找错误和饱和度指标，因为它们都很容易解释，然后是资源利用率。
# 饱和度是指资源的负载超过其处理能力，可以显示为请求队列的长度或等待时间。
# ```
# uptime
# dmesg | tail
# vmstat 1
# mpstat -P ALL 1
# pidstat 1
# iostat -xz 1
# free -m
# sar -n DEV 1
# sar -n TCP,ETCP 1
# top
# ```
# 其中一些命令需要安装 sysstat 包。这些命令公开的指标将帮助您完成USE 方法的一部分：一种定位性能瓶颈的方法。这涉及检查所有资源（CPU、内存、磁盘等）的利用率、饱和度和错误指标。还要注意检查和排除资源的时间，因为通过消除过程可以缩小要研究的目标，并指导任何后续调查。
# 以下部分总结了这些命令，并提供了来自生产系统的示例。有关这些工具的更多信息，请参阅其手册页。

# ```
# $ uptime
# 23:51:26 up 21:31, 1 user, load average: 30.02, 26.43, 19.02
# ```
# 这是查看平均负载的快捷方式，平均负载表示要运行的任务（进程）数量。在 Linux 系统上，这些数字包括要利用 CPU 运行的进程，以及在不可中断 I/O（通常是磁盘 I/O）中阻塞的进程。这可以大致了解资源负载（或需求），但如果没有其他工具，则无法正确理解。仅值得快速查看。
# 这三个数字是指数衰减的移动和平均值，常数分别为 1 分钟、5 分钟和 15 分钟。这三个数字让我们了解负载随时间的变化情况。例如，如果您被要求检查有问题的服务器，而 1 分钟的值远低于 15 分钟的值，那么您可能登录得太晚而错过了问题。
# 在上面的例子中，平均负载显示最近有所增加，1 分钟的值达到 30，而 15 分钟的值达到 19。这些数字如此之大意味着很多事情：可能是 CPU 需求；vmstat 或 mpstat 将确认，它们是此序列中的命令 3 和 4
uptime


# ```
# $ dmesg | tail
# [1880957.563150] perl invoked oom-killer: gfp_mask=0x280da, order=0, oom_score_adj=0
# [...]
# [1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child
# [1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB
# [2320864.954447] TCP: Possible SYN flooding on port 7001. Dropping request.  Check SNMP counters.
# ``` 
# 这将查看最后 10 条系统消息（如果有）。查找可能导致性能问题的错误。上面的示例包括 oom-killer 和 TCP 丢弃请求
# 不要错过这个步骤！dmesg 总是值得检查的
dmesg | tail


# ```
# $ vmstat 1
# procs ---------memory---------- ---swap-- -----io---- -system-- ------cpu-----
#  r  b swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
# 34  0    0 200889792  73708 591828    0    0     0     5    6   10 96  1  3  0  0
# 32  0    0 200889920  73708 591860    0    0     0   592 13284 4282 98  1  1  0  0
# 32  0    0 200890112  73708 591860    0    0     0     0 9501 2154 99  1  0  0  0
# 32  0    0 200889568  73712 591856    0    0     0    48 11900 2459 99  0  0  0  0
# 32  0    0 200890208  73712 591860    0    0     0     0 15898 4840 98  1  1  0  0
# ^C
# ```
# vmstat(8) 是虚拟内存统计的缩写，是一种常用工具（几十年前首次为 BSD 创建）。它在每一行上打印关键服务器统计信息的摘要。
# vmstat 运行时带有一个参数 1，用于打印一秒的摘要。输出的第一行（在此版本的 vmstat 中）包含一些列，这些列显示自启动以来的平均值，而不是前一秒的平均值。现在，请跳过第一行，除非您想了解并记住哪一列是哪一列。
# 要检查的列：
# r：在 CPU 上运行并等待轮次的进程数。这比负载平均值更能确定 CPU 饱和度，因为它不包括 I/O。解释：大于 CPU 数量的"r"值表示饱和。
# free：可用内存（以千字节为单位）。如果数字太多，无法计数，则表示可用内存足够。包含在命令 7 中的"free -m"命令更好地解释了可用内存的状态。
# si, so：换入和换出。如果这些非零，则表示内存不足。
# us、sy、id、wa、st：这些是所有 CPU 的平均 CPU 时间细目。它们是用户时间、系统时间（内核）、空闲时间、等待 I/O 和偷窃时间（由其他客户机或客户机自己的独立驱动程序域 Xen 偷窃）。
# CPU 时间细分将通过添加用户 + 系统时间来确认 CPU 是否繁忙。恒定程度的等待 I/O 指向磁盘瓶颈；这是 CPU 空闲的地方，因为任务被阻止等待待处理的磁盘 I/O。您可以将等待 I/O 视为 CPU 空闲的另一种形式，它提供了它们空闲的原因的线索。
# 系统时间对于 I/O 处理必不可少。如果系统时间平均值较高（超过 20%），则值得进一步探究：也许内核处理 I/O 的效率不高。
# 在上面的例子中，CPU 时间几乎全部处于用户级，这指向的是应用程序级使用情况。CPU 的平均利用率也远远超过 90%。这不一定是个问题；使用"r"列检查饱和度。
vmstat 1


# ```
# $ mpstat -P ALL 1
# Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86_64_ (32 CPU)
# 
# 07:38:49 PM  CPU   %usr  %nice   %sys %iowait   %irq  %soft  %steal  %guest  %gnice  %idle
# 07:38:50 PM  all  98.47   0.00   0.75    0.00   0.00   0.00    0.00    0.00    0.00   0.78
# 07:38:50 PM    0  96.04   0.00   2.97    0.00   0.00   0.00    0.00    0.00    0.00   0.99
# 07:38:50 PM    1  97.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   2.00
# 07:38:50 PM    2  98.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   1.00
# 07:38:50 PM    3  96.97   0.00   0.00    0.00   0.00   0.00    0.00    0.00    0.00   3.03
# [...]
# ```
# 此命令打印每个 CPU 的 CPU 时间明细，可用于检查不平衡情况。单个热 CPU 可以证明应用程序是单线程的。
mpstat -P ALL 1

# ```
# $ pidstat 1
# Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)
# 
# 07:41:02 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
# 07:41:03 PM     0         9    0.00    0.94    0.00    0.94     1  rcuos/0
# 07:41:03 PM     0      4214    5.66    5.66    0.00   11.32    15  mesos-slave
# 07:41:03 PM     0      4354    0.94    0.94    0.00    1.89     8  java
# 07:41:03 PM     0      6521 1596.23    1.89    0.00 1598.11    27  java
# 07:41:03 PM     0      6564 1571.70    7.55    0.00 1579.25    28  java
# 07:41:03 PM 60004     60154    0.94    4.72    0.00    5.66     9  pidstat
# 
# 07:41:03 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
# 07:41:04 PM     0      4214    6.00    2.00    0.00    8.00    15  mesos-slave
# 07:41:04 PM     0      6521 1590.00    1.00    0.00 1591.00    27  java
# 07:41:04 PM     0      6564 1573.00   10.00    0.00 1583.00    28  java
# 07:41:04 PM   108      6718    1.00    0.00    0.00    1.00     0  snmp-pass
# 07:41:04 PM 60004     60154    1.00    4.00    0.00    5.00     9  pidstat
# ^C
# ```
# Pidstat 有点像 top 的每个进程摘要，但它会打印滚动摘要而不是清除屏幕。这对于观察一段时间内的模式以及将您看到的内容（复制粘贴）记录到调查记录中非常有用。
# 上述示例表明两个 Java 进程消耗了 CPU。%CPU 列是所有 CPU 的总和；1591% 表明该 Java 进程消耗了近 16 个 CPU。
pidstat 1

# ```
# $ iostat -xz 1
# Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86_64_ (32 CPU)
# 
# avg-cpu:  %user   %nice %system %iowait  %steal   %idle
#           73.96    0.00    3.73    0.03    0.06   22.21
# 
# Device:   rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
# xvda        0.00     0.23    0.21    0.18     4.52     2.08    34.37     0.00    9.98   13.80    5.42   2.44   0.09
# xvdb        0.01     0.00    1.02    8.94   127.97   598.53   145.79     0.00    0.43    1.78    0.28   0.25   0.25
# xvdc        0.01     0.00    1.02    8.86   127.79   595.94   146.50     0.00    0.45    1.82    0.30   0.27   0.26
# dm-0        0.00     0.00    0.69    2.32    10.47    31.69    28.01     0.01    3.23    0.71    3.98   0.13   0.04
# dm-1        0.00     0.00    0.00    0.94     0.01     3.78     8.00     0.33  345.84    0.04  346.81   0.01   0.00
# dm-2        0.00     0.00    0.09    0.07     1.35     0.36    22.50     0.00    2.55    0.23    5.62   1.78   0.03
# [...]
# ^C
# ```
# 这是了解块设备（磁盘）的绝佳工具，包括所应用的工作负载和产生的性能。查找：
# r/s、w/s、rkB/s、wkB/s：这些是每秒向设备传送的读取、写入、读取 KB 和写入 KB。使用这些来表征工作负载。性能问题可能只是由于施加了过多的负载。
# await：I/O 的平均时间（以毫秒为单位）。这是应用程序所花费的时间，因为它包括排队时间和正在服务的时间。大于预期的平均时间可能表示设备饱和或设备出现问题。
# avgqu-sz：向设备发出的平均请求数。值大于 1 可能表明设备已饱和（尽管设备通常可以并行处理请求，尤其是面向多个后端磁盘的虚拟设备）。
# %util：设备利用率。这实际上是一个繁忙百分比，显示设备每秒工作的时间。大于 60% 的值通常会导致性能不佳（应该在 await 中看到），尽管这取决于设备。接近 100% 的值通常表示饱和。
# 如果存储设备是位于许多后端磁盘前面的逻辑磁盘设备，则 100% 利用率可能仅意味着某些 I/O 正在 100% 的时间内被处理，然而，后端磁盘可能远未饱和，并且可能能够处理更多的工作。
# 请记住，磁盘 I/O 性能不佳不一定是应用程序问题。通常使用许多技术来异步执行 I/O，这样应用程序就不会直接阻塞和遭受延迟（例如，读取时的预读和写入时的缓冲）。
iostat -xz 1

# ```
# $ free -m
#              total       used       free     shared    buffers     cached
# Mem:        245998      24545     221453         83         59        541
# -/+ buffers/cache:      23944     222053
# Swap:            0          0          0
# ```
# 右边两列显示：
# buffers：为缓冲区缓存，用于块设备 I/O。
# cached：用于文件系统使用的页面缓存。
# 我们只是想检查这些文件的大小是否接近于零，否则会导致更高的磁盘 I/O（使用 iostat 确认）和更差的性能。上面的示例看起来不错，每个文件都包含许多兆字节。
# “-/+ buffers/cache” 为已用内存和可用内存提供了不太容易混淆的值。Linux 使用可用内存作为缓存，但如果应用程序需要，可以快速回收。因此，某种程度上，缓存内存应该包含在可用内存列中，而这一行就是这么做的。甚至还有一个网站linuxatemyram，专门讨论这种混淆。
# 如果在 Linux 上使用 ZFS，情况可能会更加令人困惑，因为我们对某些服务就是这么做的，因为 ZFS 有自己的文件系统缓存，而 free -m 列无法正确反映这一点。系统可能看起来是可用内存不足，但实际上这些内存可以在需要时从 ZFS 缓存中获取。
free -m


# ```
# $ sar -n DEV 1
# Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015     _x86_64_    (32 CPU)
# 
# 12:16:48 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
# 12:16:49 AM      eth0  18763.00   5032.00  20686.42    478.30      0.00      0.00      0.00      0.00
# 12:16:49 AM        lo     14.00     14.00      1.36      1.36      0.00      0.00      0.00      0.00
# 12:16:49 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
# 
# 12:16:49 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
# 12:16:50 AM      eth0  19763.00   5101.00  21999.10    482.56      0.00      0.00      0.00      0.00
# 12:16:50 AM        lo     20.00     20.00      3.25      3.25      0.00      0.00      0.00      0.00
# 12:16:50 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
# ^C
# ```
# 使用此工具检查网络接口吞吐量：rxkB/s 和 txkB/s，作为工作负载的衡量标准，并检查是否已达到任何限制。在上面的例子中，eth0 接收达到 22 Mbytes/s，即 176 Mbits/sec（远低于 1 Gbit/sec 的限制）。
# 此版本还具有 %ifutil 用于设备利用率（全双工的两个方向的最大值），这也是我们使用 Brendan 的nicstat 工具来测量的。与 nicstat 一样，这很难正确实现，并且似乎在本例中不起作用（0.00）。
sar -n DEV 1


# ```
# $ sar -n TCP,ETCP 1
# Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)
# 
# 12:17:19 AM  active/s passive/s    iseg/s    oseg/s
# 12:17:20 AM      1.00      0.00  10233.00  18846.00
# 
# 12:17:19 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s
# 12:17:20 AM      0.00      0.00      0.00      0.00      0.00
# 
# 12:17:20 AM  active/s passive/s    iseg/s    oseg/s
# 12:17:21 AM      1.00      0.00   8359.00   6039.00
# 
# 12:17:20 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s
# 12:17:21 AM      0.00      0.00      0.00      0.00      0.00
# ^C
# ```
# 这是一些关键 TCP 指标的摘要。这些包括：
# active/s：每秒本地发起的 TCP 连接数（例如，通过 connect()）。
# Passive/s：每秒远程发起的 TCP 连接数（例如，通过 accept()）。
# retrans/s：每秒 TCP 重传次数。
# 主动和被动计数通常可用作服务器负载的粗略衡量标准：新接受的连接数（被动）和下游连接数（主动）。将主动视为出站，将被动视为入站可能会有所帮助，但这并不完全正确（例如，考虑本地主机到本地主机的连接）。
# 重传是网络或服务器出现问题的征兆；可能是网络不可靠（例如公共互联网），也可能是由于服务器过载并丢包。上例显示每秒只有一个新 TCP 连接。
sar -n TCP,ETCP 1


# ```
# $ top
# top - 00:15:40 up 21:56,  1 user,  load average: 31.09, 29.87, 29.92
# Tasks: 871 total,   1 running, 868 sleeping,   0 stopped,   2 zombie
# %Cpu(s): 96.8 us,  0.4 sy,  0.0 ni,  2.7 id,  0.1 wa,  0.0 hi,  0.0 si,  0.0 st
# KiB Mem:  25190241+total, 24921688 used, 22698073+free,    60448 buffers
# KiB Swap:        0 total,        0 used,        0 free.   554208 cached Mem
# 
#    PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
#  20248 root      20   0  0.227t 0.012t  18748 S  3090  5.2  29812:58 java
#   4213 root      20   0 2722544  64640  44232 S  23.5  0.0 233:35.37 mesos-slave
#  66128 titancl+  20   0   24344   2332   1172 R   1.0  0.0   0:00.07 top
#   5235 root      20   0 38.227g 547004  49996 S   0.7  0.2   2:02.74 java
#   4299 root      20   0 20.015g 2.682g  16836 S   0.3  1.1  33:14.42 java
#      1 root      20   0   33620   2920   1496 S   0.0  0.0   0:03.82 init
#      2 root      20   0       0      0      0 S   0.0  0.0   0:00.02 kthreadd
#      3 root      20   0       0      0      0 S   0.0  0.0   0:05.35 ksoftirqd/0
#      5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H
#      6 root      20   0       0      0      0 S   0.0  0.0   0:06.94 kworker/u256:0
#      8 root      20   0       0      0      0 S   0.0  0.0   2:38.05 rcu_sched
# ```
# top 命令包含我们之前检查过的许多指标。运行该命令可以很方便地查看是否与之前的命令有很大不同，这表明负载是可变的。
# top 的一个缺点是，很难看出一段时间内的模式，而使用 vmstat 和 pidstat 等提供滚动输出的工具可能会更清楚。如果您没有足够快地暂停输出（Ctrl-S 暂停，Ctrl-Q 继续），并且屏幕清空，间歇性问题的证据也可能会丢失。
top
